{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data and subset Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = pd.read_csv(\"../data_intermed/news_bert.csv\")\n",
    "news = news[news['text']!=\" \"] # remove empty entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilBert_title = np.load('../data_intermed/distilBert_title.npy')\n",
    "distilBert_text = np.load('../data_intermed/distilBert_text.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLabels(data, col_name):\n",
    "    labels = data[col_name].values\n",
    "    y = np.zeros(labels.shape)\n",
    "    y[labels == 'fake'] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44271, 768)\n",
      "22855.0 44271\n"
     ]
    }
   ],
   "source": [
    "distilBert_title = distilBert_title[news.index]\n",
    "distilBert_text = distilBert_text[news.index]\n",
    "y = createLabels(news, 'label')\n",
    "\n",
    "print(distilBert_text.shape)\n",
    "print(y.sum(), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Subset Data to only politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['politicsNews', 'worldnews', 'News', 'politics', 'Government News',\n",
       "       'left-news', 'US_News', 'Middle-east'], dtype=object)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.subject.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_p = news[news['subject'].isin(['politicsNews','politics','Government News','left-news'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "fake    12244\n",
       "true    11271\n",
       "Name: title, dtype: int64"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_p.size\n",
    "news_p.groupby('label').count().title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23515, 768)\n",
      "12244.0 44271\n"
     ]
    }
   ],
   "source": [
    "distilBert_title_p = distilBert_title[news_p.index]\n",
    "distilBert_text_p = distilBert_text[news_p.index]\n",
    "y_p = createLabels(news_p, 'label')\n",
    "\n",
    "print(distilBert_text_p.shape)\n",
    "print(y_p.sum(), len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Combine title and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilBert_mean = (distilBert_title + distilBert_text)/2\n",
    "distilBert_mean_p = (distilBert_title_p + distilBert_text_p)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilBert_title_text = np.concatenate((distilBert_title, distilBert_text),1)\n",
    "distilBert_title_text_p = np.concatenate((distilBert_title_p, distilBert_text_p),1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrModelEval(X, y, test_perc):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_perc, random_state=42)\n",
    "    clf = LogisticRegression(random_state=0, max_iter = 2000).fit(X_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    assert(y_pred_train.shape == y_train.shape)\n",
    "    assert(y_pred_test.shape == y_test.shape)\n",
    "    \n",
    "    # evaluate\n",
    "    print('training accuracy:', clf.score(X_train, y_train))\n",
    "    print('test accuracy:', clf.score(X_test, y_test))\n",
    "    print('train f-score:', f1_score(y_train, y_pred_train))\n",
    "    print('test f-score:', f1_score(y_test, y_pred_test))\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9698931256532146\n",
      "test accuracy: 0.9671457905544147\n",
      "train f-score: 0.970712669312256\n",
      "test f-score: 0.9680468645985887\n"
     ]
    }
   ],
   "source": [
    "clf_title = lrModelEval(distilBert_title, y, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9794985718819422\n",
      "test accuracy: 0.9775773195876288\n",
      "train f-score: 0.9802022678516702\n",
      "test f-score: 0.9784119106699752\n"
     ]
    }
   ],
   "source": [
    "clf_title_p = lrModelEval(distilBert_title_p, y_p, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9925154242945282\n",
      "test accuracy: 0.9888432580424367\n",
      "train f-score: 0.9927417772837246\n",
      "test f-score: 0.9891658358258558\n"
     ]
    }
   ],
   "source": [
    "clf_text = lrModelEval(distilBert_text, y, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9964455728340209\n",
      "test accuracy: 0.993298969072165\n",
      "train f-score: 0.9965841161400513\n",
      "test f-score: 0.993570722057369\n"
     ]
    }
   ],
   "source": [
    "clf_text_p = lrModelEval(distilBert_text_p, y_p, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.998550284885877\n",
      "test accuracy: 0.9958932238193019\n",
      "train f-score: 0.998595918367347\n",
      "test f-score: 0.9960180514998673\n"
     ]
    }
   ],
   "source": [
    "clf_title_text = lrModelEval(distilBert_title_text, y, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9997461123452872\n",
      "test accuracy: 0.9978092783505155\n",
      "train f-score: 0.9997560380580629\n",
      "test f-score: 0.9978989000123594\n"
     ]
    }
   ],
   "source": [
    "clf_title_text_p = lrModelEval(distilBert_title_text_p, y_p, 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svcModelEval(X, y, test_perc):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_perc, random_state=42)\n",
    "    clf = SVC().fit(X_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    assert(y_pred_train.shape == y_train.shape)\n",
    "    assert(y_pred_test.shape == y_test.shape)\n",
    "    \n",
    "    # evaluate\n",
    "    print('training accuracy:', clf.score(X_train, y_train))\n",
    "    print('test accuracy:', clf.score(X_test, y_test))\n",
    "    print('train f-score:', f1_score(y_train, y_pred_train))\n",
    "    print('test f-score:', f1_score(y_test, y_pred_test))\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9607902633087219\n",
      "test accuracy: 0.9605749486652977\n",
      "train f-score: 0.9617169755423154\n",
      "test f-score: 0.961456102783726\n"
     ]
    }
   ],
   "source": [
    "clf_svm_title = svcModelEval(distilBert_title, y, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.967185020628372\n",
      "test accuracy: 0.9686855670103093\n",
      "train f-score: 0.96811987420608\n",
      "test f-score: 0.9696212026503312\n"
     ]
    }
   ],
   "source": [
    "clf_svm_title = svcModelEval(distilBert_title_p, y_p, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9856377060786892\n",
      "test accuracy: 0.9835728952772074\n",
      "train f-score: 0.9860428543345785\n",
      "test f-score: 0.9840234322992943\n"
     ]
    }
   ],
   "source": [
    "clf_svm_text = svcModelEval(distilBert_text, y, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9871152015233259\n",
      "test accuracy: 0.9867268041237114\n",
      "train f-score: 0.9876045673810833\n",
      "test f-score: 0.9872666584250217\n"
     ]
    }
   ],
   "source": [
    "clf_svm_text_p = svcModelEval(distilBert_text_p, y_p, 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nbModelEval(X, y, test_perc):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_perc, random_state=42)\n",
    "    clf = GaussianNB().fit(X_train, y_train)\n",
    "    \n",
    "    # predict\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    assert(y_pred_train.shape == y_train.shape)\n",
    "    assert(y_pred_test.shape == y_test.shape)\n",
    "    \n",
    "    # evaluate\n",
    "    print('training accuracy:', clf.score(X_train, y_train))\n",
    "    print('test accuracy:', clf.score(X_test, y_test))\n",
    "    print('train f-score:', f1_score(y_train, y_pred_train))\n",
    "    print('test f-score:', f1_score(y_test, y_pred_test))\n",
    "    \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.8516570580897475\n",
      "test accuracy: 0.8499657768651608\n",
      "train f-score: 0.8537914534458695\n",
      "test f-score: 0.8528859060402684\n"
     ]
    }
   ],
   "source": [
    "clf_nb_title = nbModelEval(distilBert_title, y, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.8703268803554427\n",
      "test accuracy: 0.8743556701030928\n",
      "train f-score: 0.8731607375675172\n",
      "test f-score: 0.8778654641112363\n"
     ]
    }
   ],
   "source": [
    "clf_nb_title_p = nbModelEval(distilBert_title_p, y_p, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9221199554971174\n",
      "test accuracy: 0.9243668720054757\n",
      "train f-score: 0.924809582709459\n",
      "test f-score: 0.9270193514298922\n"
     ]
    }
   ],
   "source": [
    "clf_nb_text = nbModelEval(distilBert_text, y, 0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: 0.9178673437004126\n",
      "test accuracy: 0.9252577319587629\n",
      "train f-score: 0.9189426208970183\n",
      "test f-score: 0.9268046441191318\n"
     ]
    }
   ],
   "source": [
    "clf_nb_text_p = nbModelEval(distilBert_text_p, y_p, 0.33)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
